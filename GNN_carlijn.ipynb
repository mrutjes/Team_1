{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981722b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import de nodige packages\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit.Chem.rdmolfiles import MolFromXYZFile\n",
    "from functions.data_loader import data_loader\n",
    "from classes.smiles_to_graph import MolecularGraphFromSMILES\n",
    "from classes.MPNN import MPNN\n",
    "from functions.compute_loss import compute_loss\n",
    "from functions.evaluations import evaluate_yield\n",
    "from functions.evaluations import evaluate_borylation_site\n",
    "from functions.evaluations import evaluate_reactivity\n",
    "from functions.evaluations import evaluate_model\n",
    "from functions.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f48e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ae3494a",
   "metadata": {},
   "source": [
    "# Load the data and couple the SMILES to the yields and remove nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309a757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "   compound_id                                        smiles_raw  \\\n",
      "0        comp1                            C1C2=C(N=C(O2)C)C=CC=1   \n",
      "1        comp2                        C1C2=C(N=C(O2)C)C=C(Br)C=1   \n",
      "2        comp3                            C1C2=C(N=C(N2)C)C=CC=1   \n",
      "3        comp4                          C1(Cl)=CC=NC2NC(C)=CC1=2   \n",
      "4        comp5                        C1C2=C(N=C(O2)C)C=C(OC)C=1   \n",
      "..         ...                                               ...   \n",
      "78      comp88  C1C=CC=C2N(C(=O)OC(C)(C)C)C=C([Si]([H])(C)C)C=12   \n",
      "79      comp91                                    C1=CC(F)=NC=C1   \n",
      "80      comp92                                    C1=CC(F)=NC=C1   \n",
      "81      comp93                                    C1=CC(F)=NC=C1   \n",
      "82      comp97                           N1=CC=C(C(F)(F)F)C=C1Cl   \n",
      "\n",
      "   borylation_site  yield  \n",
      "0                1     68  \n",
      "1               11     86  \n",
      "2                2     94  \n",
      "3               10     72  \n",
      "4                1     81  \n",
      "..             ...    ...  \n",
      "78               1     73  \n",
      "79               1     45  \n",
      "80               2     15  \n",
      "81               7     10  \n",
      "82               2     72  \n",
      "\n",
      "[83 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yields_path = \"data/compounds_yield.csv\"\n",
    "smiles_path = \"data/compounds_smiles.csv\"\n",
    "\n",
    "df_merged = data_loader(yields_path, smiles_path)\n",
    "\n",
    "\n",
    "print(\"Merged DataFrame:\")\n",
    "print(df_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a2886",
   "metadata": {},
   "source": [
    "Convert the SMILES to Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit laat zien dat onze class werkt ->uiteindelijk overbodig denk ik\n",
    "\n",
    "# Create a molecule from a SMILES string\n",
    "smiles = \"CC(=O)O\"  \n",
    "mol_graph = MolecularGraphFromSMILES(smiles)\n",
    "\n",
    "# Visualize the molecule with bond orders\n",
    "mol_graph.visualize()\n",
    "\n",
    "# Convert to PyTorch Geometric format\n",
    "pyg_data = mol_graph.to_pyg_data()\n",
    "print(pyg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e5f5e",
   "metadata": {},
   "source": [
    "## Zet de SMILES om naar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f329e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting SMILES to graphs: 100%|██████████| 83/83 [00:00<00:00, 967.72it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graphs = []\n",
    "for _, row in tqdm(df_merged.iterrows(), total=len(df_merged), desc=\"Converting SMILES to graphs\"):\n",
    "    try:\n",
    "        graph = MolecularGraphFromSMILES(row['smiles_raw']).to_pyg_data()\n",
    "        graph.y = torch.tensor([row['yield']], dtype=torch.float)\n",
    "        graphs.append(graph)\n",
    "    except Exception as e:\n",
    "        print(f\"Fout bij SMILES: {row['smiles_raw']}, error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4939680",
   "metadata": {},
   "source": [
    "## Zet de graphs in een dataloader zodat het de GNN in kan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b196a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'borylation_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Dit werkt volgens mij niet helemaal zo want we hebben ook nog compute_loss->want \u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# want nu doet ie loss in train maar train is includes al de loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Training loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Evaluatie na training\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Carlijn\\Documents\\Master Chemistry year 1\\Machine_Learning\\Team_1\\functions\\train.py:13\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optimizer, device)\u001b[39m\n\u001b[32m      9\u001b[39m optimizer.zero_grad()\n\u001b[32m     10\u001b[39m p_borylation, reactivity_score, predicted_yield = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n\u001b[32m     12\u001b[39m loss, l_site, l_react, l_yield = compute_loss(\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     p_borylation, \u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mborylation_mask\u001b[49m,\n\u001b[32m     14\u001b[39m     reactivity_score, batch.reactivity,\n\u001b[32m     15\u001b[39m     predicted_yield, batch.y\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m loss.backward()\n\u001b[32m     19\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Carlijn\\miniconda3\\envs\\ml4chem_gnn\\Lib\\site-packages\\torch_geometric\\data\\data.py:561\u001b[39m, in \u001b[36mData.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m_store\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m object was created by an older version of PyG. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf this error occurred while loading an already existing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdataset, remove the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprocessed/\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory in the dataset\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mroot folder and try again.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Carlijn\\miniconda3\\envs\\ml4chem_gnn\\Lib\\site-packages\\torch_geometric\\data\\storage.py:96\u001b[39m, in \u001b[36mBaseStorage.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'GlobalStorage' object has no attribute 'borylation_mask'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Ik krijg een fout melding maar ChatGPT zegt dit: self.gnn_layer = NNConv(\n",
    "    #in_channels=hidden_feats,\n",
    "    #out_channels=hidden_feats,\n",
    "    #nn=edge_network,\n",
    "    #aggr='sum'\n",
    "#)\n",
    "# Split de lijst met graphs\n",
    "train_graphs, test_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Maak DataLoaders aan voor training en evaluatie\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Instellingen\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Aantal kenmerken per node en edge\n",
    "node_in_feats = train_graphs[0].x.shape[1]\n",
    "edge_in_feats = train_graphs[0].edge_attr.shape[1]\n",
    "\n",
    "# Grootte van de verborgen laag\n",
    "hidden_feats = 64 \n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialiseer model\n",
    "model = MPNN(node_in_feats=node_in_feats, edge_in_feats=edge_in_feats, hidden_feats=hidden_feats)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Dit werkt volgens mij niet helemaal zo want we hebben ook nog compute_loss->want \n",
    "    # want nu doet ie loss in train maar train is includes al de loss\n",
    "    loss = train(model, train_loader, optimizer, device)\n",
    "    print(f\"[Epoch {epoch+1}] Training loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluatie na training\n",
    "metrics = evaluate_model(model, train_loader, device)\n",
    "print(\"Train metrics:\", metrics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "# Instellingen\n",
    "k_folds = 5\n",
    "batch_size = 16\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(graphs)):\n",
    "    print(f\"\\n🟦 Fold {fold+1}/{k_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_graphs = [graphs[i] for i in train_idx]\n",
    "    val_graphs = [graphs[i] for i in val_idx]\n",
    "\n",
    "    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Init model and optimizer\n",
    "    model = MPNN(node_in_feats=128, edge_in_feats=64, hidden_feats=64).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "        print(f\"  [Epoch {epoch+1}] Loss: {loss:.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    fold_metrics = evaluate_model(model, val_loader, device)\n",
    "    print(f\"  🔎 Metrics Fold {fold+1}:\", fold_metrics)\n",
    "    all_metrics.append(fold_metrics)\n",
    "\n",
    "# Gemiddelde prestaties\n",
    "print(\"\\n📊 Gemiddelde metrics over alle folds:\")\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "avg_metrics = defaultdict(list)\n",
    "for metric_dict in all_metrics:\n",
    "    for k, v in metric_dict.items():\n",
    "        avg_metrics[k].append(v)\n",
    "\n",
    "for k, v_list in avg_metrics.items():\n",
    "    print(f\"{k}: {np.mean(v_list):.4f} ± {np.std(v_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f987d7",
   "metadata": {},
   "source": [
    "New version of code used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# --- Training Function ---\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        p_borylation, reactivity_score, predicted_yield = model(\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        )\n",
    "\n",
    "        # Losses\n",
    "        loss_bce = F.binary_cross_entropy_with_logits(p_borylation, data.p_borylation.float())\n",
    "        loss_mse_node = F.mse_loss(reactivity_score, data.reactivity_score)\n",
    "        loss_mse_graph = F.mse_loss(predicted_yield, data.y)\n",
    "\n",
    "        loss = loss_bce + loss_mse_node + loss_mse_graph\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    bce_losses = []\n",
    "    node_mse_losses = []\n",
    "    graph_mse_losses = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        p_borylation, reactivity_score, predicted_yield = model(\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        )\n",
    "\n",
    "        bce = F.binary_cross_entropy_with_logits(p_borylation, data.p_borylation.float()).item()\n",
    "        node_mse = F.mse_loss(reactivity_score, data.reactivity_score).item()\n",
    "        graph_mse = F.mse_loss(predicted_yield, data.y).item()\n",
    "\n",
    "        bce_losses.append(bce)\n",
    "        node_mse_losses.append(node_mse)\n",
    "        graph_mse_losses.append(graph_mse)\n",
    "\n",
    "    return {\n",
    "        \"BCE_loss\": np.mean(bce_losses),\n",
    "        \"Node_MSE\": np.mean(node_mse_losses),\n",
    "        \"Graph_MSE\": np.mean(graph_mse_losses)\n",
    "    }\n",
    "\n",
    "# --- Main K-Fold Loop ---\n",
    "def run_k_fold(graphs, k_folds=5, batch_size=16, num_epochs=20, learning_rate=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    all_metrics = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(graphs)):\n",
    "        print(f\"\\n🟦 Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "        train_graphs = [graphs[i] for i in train_idx]\n",
    "        val_graphs = [graphs[i] for i in val_idx]\n",
    "\n",
    "        train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = MPNN(\n",
    "            node_in_feats=graphs[0].x.size(-1),\n",
    "            edge_in_feats=graphs[0].edge_attr.size(-1),\n",
    "            hidden_feats=64\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            loss = train(model, train_loader, optimizer, device)\n",
    "            print(f\"  [Epoch {epoch+1}] Loss: {loss:.4f}\")\n",
    "\n",
    "        fold_metrics = evaluate_model(model, val_loader, device)\n",
    "        print(f\"  🔎 Metrics Fold {fold+1}:\", fold_metrics)\n",
    "        all_metrics.append(fold_metrics)\n",
    "\n",
    "    print(\"\\n📊 Gemiddelde metrics over alle folds:\")\n",
    "    avg_metrics = defaultdict(list)\n",
    "    for metric_dict in all_metrics:\n",
    "        for k, v in metric_dict.items():\n",
    "            avg_metrics[k].append(v)\n",
    "\n",
    "    for k, v_list in avg_metrics.items():\n",
    "        print(f\"{k}: {np.mean(v_list):.4f} ± {np.std(v_list):.4f}\")\n",
    "\n",
    "# --- Example usage (assuming your dataset is ready) ---\n",
    "# run_k_fold(graphs, k_folds=5, batch_size=16, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994279aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ik moet nog even kijken wat ik hiervan nodig heb als ik de k fold wil introduceren -> en of ik uberhaupt\n",
    "# hier iets van nodig heb\n",
    "# Split de lijst met graphs\n",
    "train_graphs, test_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Maak DataLoaders aan voor training en evaluatie\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit wordt miss de k fold validation geintrepeteerd-> dit zou betekenen denk ik dat\n",
    "# de vorige cell overboden zou worden\n",
    "# graphs zijn onze smiles in een lijst\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Deze getallen zijn nog arbitrary, maar dit zijn de nodige dingen die we kunnen veranderen\n",
    "# Initialisering voor de k_fold\n",
    "k_folds = 5\n",
    "batch_size = 16\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Aantal kenmerken per node en edge\n",
    "node_in_feats = 128 \n",
    "edge_in_feats = 64  \n",
    "# Grootte van de verborgen laag\n",
    "hidden_feats = 64 \n",
    "\n",
    "\n",
    "# Initialisering model\n",
    "model = MPNN(node_in_feats=node_in_feats, edge_in_feats=edge_in_feats, hidden_feats=hidden_feats)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(graphs)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    \n",
    "    train_graphs = [graphs[i] for i in train_idx]\n",
    "    test_graphs = [graphs[i] for i in test_idx]\n",
    "\n",
    "    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # of initialiseer ik het model zo\n",
    "    model = train(model, train_loader, optimizer, device)\n",
    "\n",
    "    # Voor elke batch in de train_loader (trainen per fold)\n",
    "    for batch in train_loader:\n",
    "        x = batch.x\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr = batch.edge_attr\n",
    "        y = batch.y\n",
    "        batch_vector = batch.batch\n",
    "\n",
    "        # Hier voer je het model uit, verliesfunctie berekenen, backpropagation etc.\n",
    "        # Bijvoorbeeld:\n",
    "        # output = model(x, edge_index, edge_attr, batch_vector)\n",
    "        # loss = loss_fn(output, y)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4chem_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
