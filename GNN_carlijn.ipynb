{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981722b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import de nodige packages\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Draw\n",
    "from rdkit.Chem.rdmolfiles import MolFromXYZFile\n",
    "from functions.data_loader import data_loader\n",
    "from classes.smiles_to_graph import MolecularGraphFromSMILES\n",
    "from classes.MPNN import MPNN\n",
    "from functions.compute_loss import compute_loss\n",
    "from functions.evaluations import evaluate_yield\n",
    "from functions.evaluations import evaluate_borylation_site\n",
    "from functions.evaluations import evaluate_reactivity\n",
    "from functions.evaluations import evaluate_model\n",
    "from functions.train import train_MPNN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3494a",
   "metadata": {},
   "source": [
    "# Load the data and couple the SMILES to the yields and remove nan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309a757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yields_path = \"data/compounds_yield.csv\"\n",
    "smiles_path = \"data/compounds_smiles.csv\"\n",
    "\n",
    "df_merged = data_loader(yields_path, smiles_path)\n",
    "\n",
    "\n",
    "#print(\"Merged DataFrame:\")\n",
    "#print(df_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a2886",
   "metadata": {},
   "source": [
    "Convert the SMILES to Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e5f5e",
   "metadata": {},
   "source": [
    "## Zet de SMILES om naar graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f329e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting SMILES to graphs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [00:00<00:00, 153.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "graphs = []\n",
    "for _, row in tqdm(df_merged.iterrows(), total=len(df_merged), desc=\"Converting SMILES to graphs\"):\n",
    "    try:\n",
    "        mol_graph = MolecularGraphFromSMILES(row['smiles_raw'])\n",
    "        mol = Chem.MolFromSmiles(row['smiles_raw'])  # extra RDKit mol object\n",
    "        num_atoms = mol.GetNumAtoms() if mol is not None else -1\n",
    "\n",
    "        borylation_index = row['borylation_site']\n",
    "\n",
    "        # Debug print vÃ³Ã³r de fout\n",
    "        if not (0 <= borylation_index < num_atoms):\n",
    "            raise IndexError(f\"index {borylation_index} is out of bounds for molecule with {num_atoms} atoms\")\n",
    "\n",
    "        graph = mol_graph.to_pyg_data(\n",
    "            borylation_index=borylation_index,\n",
    "            yield_value=row['yield']\n",
    "        )\n",
    "        graphs.append(graph)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nðŸš¨ Fout bij SMILES: {row['smiles_raw']}\")\n",
    "        print(f\"  - borylation_site: {row['borylation_site']}\")\n",
    "        mol = Chem.MolFromSmiles(row['smiles_raw'])\n",
    "        if mol:\n",
    "            print(f\"  - aantal atomen in RDKit mol: {mol.GetNumAtoms()}\")\n",
    "        else:\n",
    "            print(\"  - RDKit kon mol niet parsen!\")\n",
    "        print(f\"  - foutmelding: {e}\")\n",
    "\n",
    "# Verdeel de data in train, validatie en test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Eerste splitsing: 85% train+val, 15% test\n",
    "train_val_graphs, test_graphs = train_test_split(\n",
    "    graphs, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# Tweede splitsing: 70/15 = 70/85 â‰ˆ 0.8235 voor train\n",
    "train_graphs, val_graphs = train_test_split(\n",
    "    train_val_graphs, test_size=0.1765, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4939680",
   "metadata": {},
   "source": [
    "## Zet de graphs in een dataloader zodat het de GNN in kan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b196a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Training loss: 427.7886\n",
      "[Epoch 2] Training loss: 408.7964\n",
      "[Epoch 3] Training loss: 393.6932\n",
      "[Epoch 4] Training loss: 358.3435\n",
      "[Epoch 5] Training loss: 307.5023\n",
      "[Epoch 6] Training loss: 238.3885\n",
      "[Epoch 7] Training loss: 157.9392\n",
      "[Epoch 8] Training loss: 93.4265\n",
      "[Epoch 9] Training loss: 84.3032\n",
      "[Epoch 10] Training loss: 118.3759\n",
      "[Epoch 11] Training loss: 121.0190\n",
      "[Epoch 12] Training loss: 87.8077\n",
      "[Epoch 13] Training loss: 70.7335\n",
      "[Epoch 14] Training loss: 75.5974\n",
      "[Epoch 15] Training loss: 81.4142\n",
      "[Epoch 16] Training loss: 84.2907\n",
      "[Epoch 17] Training loss: 82.8874\n",
      "[Epoch 18] Training loss: 74.6385\n",
      "[Epoch 19] Training loss: 72.3350\n",
      "[Epoch 20] Training loss: 70.3302\n",
      "Train metrics: {'yield_MSE': 713.937, 'yield_MAE': 21.340105, 'yield_R2': -0.014420280016468556, 'site_Accuracy': 0.9027303754266212, 'site_Precision': 0.0, 'site_Recall': 0.0, 'site_F1': 0.0, 'site_AUC': 0.3997114714953736, 'react_MSE': 0.005867216, 'react_Spearman': nan, 'react_Pearson': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sobo/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4878: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n",
      "/opt/anaconda3/envs/sobo/lib/python3.9/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "# Instellingen\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Aantal kenmerken per node en edge\n",
    "node_in_feats = train_graphs[0].x.shape[1]\n",
    "edge_in_feats = train_graphs[0].edge_attr.shape[1]\n",
    "\n",
    "# Grootte van de verborgen laag\n",
    "hidden_feats = 64 \n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialiseer model\n",
    "model = MPNN(node_in_feats=node_in_feats, edge_in_feats=edge_in_feats, hidden_feats=hidden_feats)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Dit werkt volgens mij niet helemaal zo want we hebben ook nog compute_loss->want \n",
    "    # want nu doet ie loss in train maar train is includes al de loss\n",
    "    loss = train_MPNN_model(model, train_loader, optimizer, device)\n",
    "    print(f\"[Epoch {epoch+1}] Training loss: {loss:.4f}\")\n",
    "\n",
    "# Evaluatie na training\n",
    "metrics = evaluate_model(model, train_loader, device)\n",
    "print(\"Train metrics:\", metrics)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "# Instellingen\n",
    "k_folds = 5\n",
    "batch_size = 16\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(graphs)):\n",
    "    print(f\"\\nðŸŸ¦ Fold {fold+1}/{k_folds}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_graphs = [graphs[i] for i in train_idx]\n",
    "    val_graphs = [graphs[i] for i in val_idx]\n",
    "\n",
    "    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Init model and optimizer\n",
    "    model = MPNN(node_in_feats=128, edge_in_feats=64, hidden_feats=64).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "        print(f\"  [Epoch {epoch+1}] Loss: {loss:.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    fold_metrics = evaluate_model(model, val_loader, device)\n",
    "    print(f\"  ðŸ”Ž Metrics Fold {fold+1}:\", fold_metrics)\n",
    "    all_metrics.append(fold_metrics)\n",
    "\n",
    "# Gemiddelde prestaties\n",
    "print(\"\\nðŸ“Š Gemiddelde metrics over alle folds:\")\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "avg_metrics = defaultdict(list)\n",
    "for metric_dict in all_metrics:\n",
    "    for k, v in metric_dict.items():\n",
    "        avg_metrics[k].append(v)\n",
    "\n",
    "for k, v_list in avg_metrics.items():\n",
    "    print(f\"{k}: {np.mean(v_list):.4f} Â± {np.std(v_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f987d7",
   "metadata": {},
   "source": [
    "New version of code used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# --- Training Function ---\n",
    "def train(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        p_borylation, reactivity_score, predicted_yield = model(\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        )\n",
    "\n",
    "        # Losses\n",
    "        loss_bce = F.binary_cross_entropy_with_logits(p_borylation, data.p_borylation.float())\n",
    "        loss_mse_node = F.mse_loss(reactivity_score, data.reactivity_score)\n",
    "        loss_mse_graph = F.mse_loss(predicted_yield, data.y)\n",
    "\n",
    "        loss = loss_bce + loss_mse_node + loss_mse_graph\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# --- Evaluation Function ---\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    bce_losses = []\n",
    "    node_mse_losses = []\n",
    "    graph_mse_losses = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        p_borylation, reactivity_score, predicted_yield = model(\n",
    "            data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        )\n",
    "\n",
    "        bce = F.binary_cross_entropy_with_logits(p_borylation, data.p_borylation.float()).item()\n",
    "        node_mse = F.mse_loss(reactivity_score, data.reactivity_score).item()\n",
    "        graph_mse = F.mse_loss(predicted_yield, data.y).item()\n",
    "\n",
    "        bce_losses.append(bce)\n",
    "        node_mse_losses.append(node_mse)\n",
    "        graph_mse_losses.append(graph_mse)\n",
    "\n",
    "    return {\n",
    "        \"BCE_loss\": np.mean(bce_losses),\n",
    "        \"Node_MSE\": np.mean(node_mse_losses),\n",
    "        \"Graph_MSE\": np.mean(graph_mse_losses)\n",
    "    }\n",
    "\n",
    "# --- Main K-Fold Loop ---\n",
    "def run_k_fold(graphs, k_folds=5, batch_size=16, num_epochs=20, learning_rate=1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    all_metrics = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(graphs)):\n",
    "        print(f\"\\nðŸŸ¦ Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "        train_graphs = [graphs[i] for i in train_idx]\n",
    "        val_graphs = [graphs[i] for i in val_idx]\n",
    "\n",
    "        train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = MPNN(\n",
    "            node_in_feats=graphs[0].x.size(-1),\n",
    "            edge_in_feats=graphs[0].edge_attr.size(-1),\n",
    "            hidden_feats=64\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            loss = train(model, train_loader, optimizer, device)\n",
    "            print(f\"  [Epoch {epoch+1}] Loss: {loss:.4f}\")\n",
    "\n",
    "        fold_metrics = evaluate_model(model, val_loader, device)\n",
    "        print(f\"  ðŸ”Ž Metrics Fold {fold+1}:\", fold_metrics)\n",
    "        all_metrics.append(fold_metrics)\n",
    "\n",
    "    print(\"\\nðŸ“Š Gemiddelde metrics over alle folds:\")\n",
    "    avg_metrics = defaultdict(list)\n",
    "    for metric_dict in all_metrics:\n",
    "        for k, v in metric_dict.items():\n",
    "            avg_metrics[k].append(v)\n",
    "\n",
    "    for k, v_list in avg_metrics.items():\n",
    "        print(f\"{k}: {np.mean(v_list):.4f} Â± {np.std(v_list):.4f}\")\n",
    "\n",
    "# --- Example usage (assuming your dataset is ready) ---\n",
    "# run_k_fold(graphs, k_folds=5, batch_size=16, num_epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994279aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ik moet nog even kijken wat ik hiervan nodig heb als ik de k fold wil introduceren -> en of ik uberhaupt\n",
    "# hier iets van nodig heb\n",
    "# Split de lijst met graphs\n",
    "train_graphs, test_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Maak DataLoaders aan voor training en evaluatie\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dit wordt miss de k fold validation geintrepeteerd-> dit zou betekenen denk ik dat\n",
    "# de vorige cell overboden zou worden\n",
    "# graphs zijn onze smiles in een lijst\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Deze getallen zijn nog arbitrary, maar dit zijn de nodige dingen die we kunnen veranderen\n",
    "# Initialisering voor de k_fold\n",
    "k_folds = 5\n",
    "batch_size = 16\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Aantal kenmerken per node en edge\n",
    "node_in_feats = 128 \n",
    "edge_in_feats = 64  \n",
    "# Grootte van de verborgen laag\n",
    "hidden_feats = 64 \n",
    "\n",
    "\n",
    "# Initialisering model\n",
    "model = MPNN(node_in_feats=node_in_feats, edge_in_feats=edge_in_feats, hidden_feats=hidden_feats)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(graphs)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    \n",
    "    train_graphs = [graphs[i] for i in train_idx]\n",
    "    test_graphs = [graphs[i] for i in test_idx]\n",
    "\n",
    "    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # of initialiseer ik het model zo\n",
    "    model = train(model, train_loader, optimizer, device)\n",
    "\n",
    "    # Voor elke batch in de train_loader (trainen per fold)\n",
    "    for batch in train_loader:\n",
    "        x = batch.x\n",
    "        edge_index = batch.edge_index\n",
    "        edge_attr = batch.edge_attr\n",
    "        y = batch.y\n",
    "        batch_vector = batch.batch\n",
    "\n",
    "        # Hier voer je het model uit, verliesfunctie berekenen, backpropagation etc.\n",
    "        # Bijvoorbeeld:\n",
    "        # output = model(x, edge_index, edge_attr, batch_vector)\n",
    "        # loss = loss_fn(output, y)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sobo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
